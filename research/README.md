# CognOS Research Experiments

**Monte Carlo epistemic sampling** for evaluating CognOS architecture.

ðŸ“– **See [TEST_PROJECT.md](TEST_PROJECT.md) for full research design.**  
ðŸ”§ **See [ENVIRONMENT_SETUP.md](ENVIRONMENT_SETUP.md) for local Ollama setup.**

---

## Quick Start

**Rekommenderad setup (avoids venv issues on mounted filesystem):**

```bash
# Setup environment in home directory
cd /media/bjorn/iic/cognos-standalone/research
./setup_home_env.sh

# Run experiments from ~/tests
cd ~/tests/cognos-research
./run_exp_001.sh
```

**Se [~/tests/cognos-research/QUICKSTART.md](~/tests/cognos-research/QUICKSTART.md) fÃ¶r detaljer.**

---

## Structure

```
research/
â”œâ”€â”€ TEST_PROJECT.md                     # ðŸŽ¯ Complete research design
â”œâ”€â”€ ENVIRONMENT_SETUP.md                # ðŸ”§ Ollama + venv setup
â”œâ”€â”€ llm_backend.py                      # Unified LLM interface
â”œâ”€â”€ requirements.txt                    # Dependencies
â”œâ”€â”€ setup_research_env.sh               # Quick setup script
â”œâ”€â”€ run_exp_001_divergence.py           # Experiment 1 runner
â”œâ”€â”€ metrics.py                          # Metric implementations
â”œâ”€â”€ experiment_runner.py                # N-iteration runner
â”œâ”€â”€ exp_001_divergence/                 # Experiment 1: Activation Rate
â”‚   â”œâ”€â”€ config.yaml                     
â”‚   â””â”€â”€ reflection.md                  
â”œâ”€â”€ exp_002_epistemic_gain/             # Experiment 2: vs Baseline
â”‚   â”œâ”€â”€ config.yaml                     
â”‚   â””â”€â”€ reflection.md                  
â””â”€â”€ exp_003_illposed/                   # Experiment 3: Bad Question Detection
    â”œâ”€â”€ config.yaml                     
    â””â”€â”€ reflection.md                  
```

---

## The Research Questions

### 1ï¸âƒ£ Divergence Activation Rate
**Hur ofta aktiveras synthesis nÃ¤r LLM rÃ¶star?**

### 2ï¸âƒ£ Epistemic Gain vs Baseline
**Ger CognOS mÃ¤tbar fÃ¶rbÃ¤ttring jÃ¤mfÃ¶rt med direct LLM query?**

### 3ï¸âƒ£ Ill-Posed Detection
**Kan CognOS identifiera dÃ¥liga frÃ¥gor?**

---

## ðŸ”¥ Starkaste Forskningsbidraget

**Inte confidence-formeln.**

**Utan:**

> **Conflict â†’ Assumptions â†’ Geometry â†’ Integration â†’ Meta-loop**

Detta Ã¤r originellt. Detta Ã¤r vad papers ska handla om.

---

## 3 Core Experiments

### 1ï¸âƒ£ Divergence Activation Rate (`exp_001_divergence`)
**FrÃ¥ga:** Hur ofta aktiveras synthesis?

**Metrics:**
- divergence_detected_rate
- synthesis_success_rate  
- convergence_depth

**Why publishable:** Bevisar att arkitekturen **faktiskt fungerar**, inte bara Ã¤r teori.

### 2ï¸âƒ£ Epistemic Gain vs Baseline (`exp_002_epistemic_gain`)
**FrÃ¥ga:** Ã„r CognOS bÃ¤ttre Ã¤n direct LLM query?

**Metrics:**
- clarity_score (1-5)
- actionability_score (1-5)
- hallucination_detection

**Why publishable:** Starkt paper-material. Visar **practical utility**.

### 3ï¸âƒ£ Ill-Posed Detection (`exp_003_illposed`)
**FrÃ¥ga:** Kan CognOS identifiera dÃ¥liga frÃ¥gor?

**Metrics:**
- detection_accuracy
- reframing_success_rate
- false_positive_rate

**Why publishable:** DÃ¤r CognOS ska excellera. Divergence semantics Ã¤r gjord fÃ¶r detta.

---

## Environment Setup

**Rekommenderad lokal setup med Ollama:**

```bash
cd /media/bjorn/iic/cognos-standalone/research

# Auto-setup
./setup_research_env.sh

# Or manually:
python3 -m venv --copies .venv  # Use --copies for mounted filesystems
source .venv/bin/activate
pip install -r requirements.txt
```

**Du har redan dessa Ollama-modeller:**
- `qwen2.5:7b` â€” **Rekommenderad** (bÃ¤sta reasoning)
- `phi3:mini` â€” Snabbare fÃ¶r tester
- `tinyllama` â€” Mycket snabb men svag

**Se [ENVIRONMENT_SETUP.md](ENVIRONMENT_SETUP.md) fÃ¶r detaljer om modellval.**

---

## Running Experiments

**Aktivera environment:**
```bash
cd /media/bjorn/iic/cognos-standalone/research
source .venv/bin/activate
```

**KÃ¶r experiment 1:**
```bash
python run_exp_001_divergence.py
```

**LLM Backend (auto-detect):**
1. FÃ¶rsÃ¶ker Ollama fÃ¶rst (`qwen2.5:7b`)
2. Fallback till Groq om GROQ_API_KEY satt
3. Fallback till Mock fÃ¶r testing

**Monte Carlo iteration:**
```python
for i in range(N):
    result = run_orchestrator(question)
    log_results(result)

aggregate_metrics()
```

**N = 30-50 per frÃ¥ga** rÃ¤cker fÃ¶r publication.

---

## Output Structure

**Efter kÃ¶rning:**
```
exp_XXX/
  â”œâ”€â”€ config.yaml         # Reproducible settings
  â”œâ”€â”€ raw_data.json       # All iterations with full trace
  â”œâ”€â”€ metrics.json        # Computed metrics
  â””â”€â”€ reflection.md       # 1-page analysis (fill in observations)
```

---

## Analysis Workflow

1. **Run experiment** â†’ generates raw_data.json + metrics.json
2. **Review data** â†’ look for patterns
3. **Fill reflection.md** â†’ observations, architectural implications
4. **Aggregate** â†’ compare across experiments
5. **Write paper** â†’ TEST_PROJECT.md har struktur

---

## Publication Timeline

| Week | Action | Output |
|------|--------|--------|
| 1 | Run exp_001_divergence | Activation data |
| 2 | Run exp_002_epistemic_gain | Baseline comparison |
| 3 | Run exp_003_illposed | Detection accuracy |
| 4 | Fill reflection.md for all 3 | Qualitative insights |
| 5 | Aggregate + draft paper | First version |
| 6 | Iterate + submit | ArXiv/conference |

**Paper title:**  
*"CognOS: A Recursive Epistemic Validation Framework for LLM Systems"*

**Key contribution:**  
> Conflict â†’ Assumptions â†’ Geometry â†’ Integration â†’ Meta-loop

---

## Reflection Template

Each experiment gets 1 page:

```markdown
# Experiment XXX

## Objective
What we tested.

## Method  
How we tested (N iterations, metrics).

## Observations
What we saw.

## Unexpected Findings
Surprises, edge cases.

## Architectural Implications
What this tells us about CognOS design.

## Next Steps
What to test/fix next.
```

---

## Status

- âœ… Research design (TEST_PROJECT.md)
- âœ… Environment setup (ENVIRONMENT_SETUP.md)
- âœ… LLM backend (Ollama support)
- âœ… 3 experiment configurations
- âœ… Reflection templates
- â³ **Run experiments** (N=30-50 per question)
- â³ **Fill reflections**
- â³ **Write paper**

---

**Remember:** Det starkaste bidraget Ã¤r arkitekturen, inte metrics.

> Conflict â†’ Assumptions â†’ Geometry â†’ Integration â†’ Meta-loop

**Detta Ã¤r vad vi publicerar.**
