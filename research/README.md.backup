# CognOS Research Experiments

**Monte Carlo epistemic sampling** for evaluating CognOS architecture.

ðŸ“– **See [TEST_PROJECT.md](TEST_PROJECT.md) for full research design.**

---

## Structure

```
research/
â”œâ”€â”€ TEST_PROJECT.md                     # ðŸŽ¯ Complete research design
â”œâ”€â”€ metrics.py                          # Metric implementations
â”œâ”€â”€ experiment_runner.py                # N-iteration runner
â”œâ”€â”€ exp_001_divergence/                 # Experiment 1: Activation Rate
â”‚   â”œâ”€â”€ config.yaml                     
â”‚   â””â”€â”€ reflection.md                  
â”œâ”€â”€ exp_002_epistemic_gain/             # Experiment 2: vs Baseline
â”‚   â”œâ”€â”€ config.yaml                     
â”‚   â””â”€â”€ reflection.md                  
â””â”€â”€ exp_003_illposed/                   # Experiment 3: Bad Question Detection
    â”œâ”€â”€ config.yaml                     
    â””â”€â”€ reflection.md                  
```

---

## The Research Questions

### 1ï¸âƒ£ Divergence Activation Rate
**Hur ofta aktiveras synthesis nÃ¤r LLM rÃ¶star?**

### 2ï¸âƒ£ Epistemic Gain vs Baseline
**Ger CognOS mÃ¤tbar fÃ¶rbÃ¤ttring jÃ¤mfÃ¶rt med direct LLM query?**

### 3ï¸âƒ£ Ill-Posed Detection
**Kan CognOS identifiera dÃ¥liga frÃ¥gor?**

---

## ðŸ”¥ Starkaste Forskningsbidraget

**Inte confidence-formeln.**

**Utan:**

> **Conflict â†’ Assumptions â†’ Geometry â†’ Integration â†’ Meta-loop**

Detta Ã¤r originellt. Detta Ã¤r vad papers ska handla om.

---

## 3 Core Experiments

### 1ï¸âƒ£ Divergence Activation Rate (`exp_001_divergence`)
**FrÃ¥ga:** Hur ofta aktiveras synthesis?

**Metrics:**
- divergence_detected_rate
- synthesis_success_rate  
- convergence_depth

**Why publishable:** Bevisar att arkitekturen **faktiskt fungerar**, inte bara Ã¤r teori.

### 2ï¸âƒ£ Epistemic Gain vs Baseline (`exp_002_epistemic_gain`)
**FrÃ¥ga:** Ã„r CognOS bÃ¤ttre Ã¤n direct LLM query?

**Metrics:**
- clarity_score (1-5)
- actionability_score (1-5)
- hallucination_detection

**Why publishable:** Starkt paper-material. Visar **practical utility**.

### 3ï¸âƒ£ Ill-Pos:
```bash
cd /media/bjorn/iic/cognos-standalone/research

# Run experiment 1
python run_exp_001_divergence.py

# Run experiment 2  
python run_exp_002_epistemic_gain.py

# Run experiment 3
python run_exp_003_illposed.py
```

### Iteration Protocol

```python
for i in range(N):
    result = run_orchestrator(question)
    log_results(result)

aggregate_metrics()
```

**N = 30-50 per frÃ¥ga** rÃ¤cker fÃ¶r publication.
cd /media/bjorn/iic/cognos-standalone
python research/run_experiment_001.py
```

### With real Groq API:
```bash
export GROQ_API_KEY=your_key_here
python research/run_experiment_001.py
```

### Create custom experiment:
1. Copy `config.yaml` template
2. Add your questions with `ground_truth`
3. Run with `ExperimentRunner`

---

## Output Structure

**After running experiments:**
```
exp_XXX/
  â”œâ”€â”€ config.yaml         # Reproducible settings
  â”œâ”€â”€ raw_data.json       # All iterations with full trace
  â”œâ”€â”€ metrics.csv         # Computed metrics
  â””â”€â”€ reflection.md       # 1-page analysis (fill in observations)
```

---

## Analysis Workflow

1. **Run experiment** â†’ generates raw_data.json + metrics.csv
2. **Review data** â†’ look for patterns
3. **Fill reflection.md** â†’ observations, architectural implications
4. **Aggregate** â†’ compare across experiments
5. **Write paper** â†’ TEST_PROJECT.md har struktur

---

## Publication Timeline

| Week | Action | Output |
|------|--------|--------|
| 1 | Run exp_001_divergence | Activation data |
| 2 | Run exp_002_epistemic_gain | Baseline comparison |
| 3 | Run exp_003_illposed | Detection accuracy |
| 4 | Fill reflection.md for all 3 | Qualitative insights |
| 5 | Aggregate + draft paper | First version |
| 6 | Iterate + submit | ArXiv/conference |

**Paper title:**  
*"CognOS: A Recursive Epistemic Validation Framework for LLM Systems"*

**Key contribution:**  
> Conflict â†’ Assumptions â†’ Geometry â†’ Integration â†’ Meta-loop

---

## Reflection Template

Each experiment gets 1 page:

```markdown
# Experiment XXX

## Objective
What we tested.

## Method  
How we tested (N iterations, metrics).

## Observations
What we saw.

## Unexpected Findings
Surprises, edge cases.

## Architectural Implications
What this tells us about CognOS design.

## Next Steps
What to test/fix next.
```Status

- âœ… Research design (TEST_PROJECT.md)
- âœ… 3 experiment configurations
- âœ… Reflection templates
- â³ **Run experiments** (N=30-50 per question)
- â³ **Fill reflections**
- â³ **Write paper**

---

**Remember:** Det starkaste bidraget Ã¤r arkitekturen, inte metrics.

> Conflict â†’ Assumptions â†’ Geometry â†’ Integration â†’ Meta-loop

**Detta Ã¤r vad vi publicerar

**This is Monte Carlo epistemic sampling.**  
**This is publication-ready research structure.**  
**This is how you prove CognOS works.**
